{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Градиентный бустинг_Сравнение_Часть1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-JZUGrczchd"
      },
      "source": [
        "# Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5pp1QW8y2fa"
      },
      "source": [
        "**Gradient Boosting** относится к классу алгоритмов ансамблевого машинного обучения, которые можно использовать для задач классификации или регрессионного прогнозного моделирования.\n",
        "\n",
        "Ниже приведен пример реализации Градиентного Бустинга с использованием библиотек: **Sklearn, Xgboost, LightGBM, CatBoost**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcSVac_azhl1"
      },
      "source": [
        "### План ноутбука:\n",
        "\n",
        "- Gradient Boosting с использованием Scikit-Learn\n",
        "    - Gradient Boosting\n",
        "    - Histogram-Based Gradient Boosting\n",
        "- Gradient Boosting с использованием XGBoost\n",
        "    - XGBoost для задачи Классификации\n",
        "    - XGBoost для задачи Регрессии\n",
        "- Gradient Boosting с использованием LightGBM\n",
        "    - LightGBM для задачи Классификации\n",
        "    - LightGBM для задачи Регрессии\n",
        "- Gradient Boosting с использованием CatBoost\n",
        "    - CatBoost для задачи Классификации\n",
        "    - CatBoost для задачи Регрессии"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA-41Kq_yxDF"
      },
      "source": [
        "## 1. Создадим искусственный датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSboW3Qpwo7x",
        "outputId": "4a18b2a4-0831-4223-a4c1-fbb04894b7d3"
      },
      "source": [
        "# test classification dataset\n",
        "from sklearn.datasets import make_classification\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 10) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5ru-A2Lw0kb",
        "outputId": "17701b0e-38f3-4cb9-a505-9b4d30f58238"
      },
      "source": [
        "# test regression dataset\n",
        "from sklearn.datasets import make_regression\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 10) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ4ncKiyw59A"
      },
      "source": [
        "# Gradient Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfKT59qExFz_"
      },
      "source": [
        "### Gradient Boosting Machine for Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxG6Nj4aw7i0",
        "outputId": "94aad1b9-ca21-436c-e142-454a5633d27a"
      },
      "source": [
        "# gradient boosting for classification in scikit-learn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "# evaluate the model\n",
        "model = GradientBoostingClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = GradientBoostingClassifier()\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.915 (0.026)\n",
            "Prediction: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9XAP2ZmxI6i"
      },
      "source": [
        "### Gradient Boosting Machine for Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayAC3TNMw70L",
        "outputId": "55de749c-ef68-4e12-f021-486cff7d098d"
      },
      "source": [
        "# gradient boosting for regression in scikit-learn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
        "# evaluate the model\n",
        "model = GradientBoostingRegressor()\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = GradientBoostingRegressor()\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [[2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %.3f' % yhat[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: -11.864 (1.106)\n",
            "Prediction: -80.661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJi5t9ZzxOkT"
      },
      "source": [
        "# Histogram-Based Gradient Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCLpeqioxfDB"
      },
      "source": [
        "### Histogram-Based Gradient Boosting Machine for Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTu7ohkJw72g",
        "outputId": "a95ef713-a10e-4d80-cf9c-ff625f322dc9"
      },
      "source": [
        "# histogram-based gradient boosting for classification in scikit-learn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "# evaluate the model\n",
        "model = HistGradientBoostingClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = HistGradientBoostingClassifier()\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.935 (0.024)\n",
            "Prediction: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y51G8O6pxa7U"
      },
      "source": [
        "**Примечание.** Ваши результаты могут отличаться из-за стохастической природы алгоритма или процедуры оценки или различий в числовой точности. Попробуйте повторить пример несколько раз и сравните средний результат. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU7FleZUxgfv"
      },
      "source": [
        "### Histogram-Based Gradient Boosting Machine for Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo4Z01s2xPot",
        "outputId": "edc69805-f992-4e6d-f348-eaf18b28a5f7"
      },
      "source": [
        "# histogram-based gradient boosting for regression in scikit-learn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
        "# evaluate the model\n",
        "model = HistGradientBoostingRegressor()\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = HistGradientBoostingRegressor()\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [[2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %.3f' % yhat[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: -12.723 (1.540)\n",
            "Prediction: -77.837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03yBGlU4xopU"
      },
      "source": [
        "# Gradient Boosting With XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPyz3DTWxtmy"
      },
      "source": [
        "### xgboost for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ea3G3AzuJGg"
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0qGjIGXw75f",
        "outputId": "b9917a25-8bdb-4969-964d-d6bfd11c6394"
      },
      "source": [
        "# xgboost for classification\n",
        "from numpy import asarray\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "# evaluate the model\n",
        "model = XGBClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]\n",
        "row = asarray(row).reshape((1, len(row)))\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.919 (0.026)\n",
            "Prediction: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6cQVjaYxyON"
      },
      "source": [
        "### xgboost for regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnksiv-8xsz5",
        "outputId": "e8da8825-3bb4-4274-bb2c-437d4eac55ac"
      },
      "source": [
        "# xgboost for regression\n",
        "from numpy import asarray\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
        "\n",
        "# evaluate the model\n",
        "model = XGBRegressor(objective='reg:squarederror')\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = XGBRegressor(objective='reg:squarederror')\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]\n",
        "row = asarray(row).reshape((1, len(row)))\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %.3f' % yhat[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: -12.083 (1.259)\n",
            "Prediction: -77.347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4qQugw3x2YF"
      },
      "source": [
        "# Gradient Boosting With LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNTJSgmdx9H_"
      },
      "source": [
        "### lightgbm for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk32_5jSxxR1",
        "outputId": "99359099-eeb1-4a2f-cfc6-1fdc58a0a909"
      },
      "source": [
        "# lightgbm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "# evaluate the model\n",
        "\n",
        "model = LGBMClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = LGBMClassifier()\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.934 (0.021)\n",
            "Prediction: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFg4pLK5yBMW"
      },
      "source": [
        "### lightgbm for regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNidCZk5vHiH"
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frPSYwF8x_zP",
        "outputId": "8ff8172a-fe5f-46ff-92e7-15e16c2dae3b"
      },
      "source": [
        "# lightgbm for regression\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
        "# evaluate the model\n",
        "model = LGBMRegressor()\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = LGBMRegressor()\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [[2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %.3f' % yhat[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: -12.739 (1.408)\n",
            "Prediction: -82.040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvcUBd_SyE4P"
      },
      "source": [
        "# Gradient Boosting with CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7P-eEknyekn"
      },
      "source": [
        "Основное преимущество CatBoost (помимо повышения скорости вычислений) - поддержка категориальных входных переменных. Это дает библиотеке название CatBoost, что означает “Category Gradient Boosting.”. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg2jtVGMx8HH",
        "outputId": "4a765085-28b7-4624-aa31-5d8e7541b8d4"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/37/bc4e0ddc30c07a96482abf1de7ed1ca54e59bba2026a33bca6d2ef286e5b/catboost-0.24.4-cp36-none-manylinux1_x86_64.whl (65.7MB)\n",
            "\u001b[K     |████████████████████████████████| 65.8MB 96kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1yWnD7byo59"
      },
      "source": [
        "### catboost for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6a4zaxIymAW",
        "outputId": "a17e21e3-7077-46e1-83ba-16cc423ac82a"
      },
      "source": [
        "# catboost for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "# evaluate the model\n",
        "model = CatBoostClassifier(verbose=0, n_estimators=100)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = CatBoostClassifier(verbose=0, n_estimators=100)\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.926 (0.026)\n",
            "Prediction: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdgyQ6PxysaN"
      },
      "source": [
        "### catboost for regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_OJ1bb3ypqo",
        "outputId": "6c71699d-1d3b-4c4c-e082-7b5ea87a3ed6"
      },
      "source": [
        "# catboost for regression\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
        "# evaluate the model\n",
        "model = CatBoostRegressor(verbose=0, n_estimators=100)\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = CatBoostRegressor(verbose=0, n_estimators=100)\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [[2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %.3f' % yhat[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: -9.623 (0.930)\n",
            "Prediction: -87.936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIzy1MzMcmJ2"
      },
      "source": [
        "# Models Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8sRi6QacCBU"
      },
      "source": [
        "\n",
        "| Model        | Classification score | Regression score (MAE)| \n",
        "| ------------- |------:|------:|\n",
        "| `GBM (sklearn)`      | 0.915| -11.864|\n",
        "| `Histogram-based GBM (sklearn)`      | 0.935| -12.723|\n",
        "| `LightGBM`      | 0.934| -12.739|\n",
        "| `XGBoost`      | 0.919|  -12.083|\n",
        "| `Catboost`      | 0.926| -9.623|\n",
        "\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AqDS2UGytOn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}